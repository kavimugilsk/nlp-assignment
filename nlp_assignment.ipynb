{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr5pHKFGZXdj",
        "outputId": "ee0298ba-7645-4fe0-b230-b4a99f4137da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams:\n",
            "<FreqDist with 51 samples and 80 outcomes>\n",
            "\n",
            "Bigrams:\n",
            "<FreqDist with 73 samples and 79 outcomes>\n",
            "\n",
            "Trigrams:\n",
            "<FreqDist with 77 samples and 78 outcomes>\n",
            "\n",
            "Bigram Probabilities:\n",
            "natural: {'language': 0.75, ')': 0.25}\n",
            "language: {'processing': 0.25, 'understanding': 0.25, '.': 0.25, 'generation': 0.25}\n",
            "processing: {'(': 1.0}\n",
            "(: {'nlp': 0.3333333333333333, 'ai': 0.3333333333333333, 'natural': 0.3333333333333333}\n",
            "nlp: {'tasks': 0.5, ')': 0.25, 'is': 0.25}\n",
            "): {'is': 0.3333333333333333, 'concerned': 0.3333333333333333, 'languages': 0.3333333333333333}\n",
            "is: {'a': 0.5, 'related': 0.5}\n",
            "a: {'subfield': 1.0}\n",
            "subfield: {'of': 1.0}\n",
            "of: {'the': 0.5, 'artificial': 0.25, 'human-computer': 0.25}\n",
            "artificial: {'intelligence': 1.0}\n",
            "intelligence: {'(': 1.0}\n",
            "ai: {')': 1.0}\n",
            "concerned: {'with': 1.0}\n",
            "with: {'the': 1.0}\n",
            "the: {'interactions': 0.25, 'area': 0.25, 'meaning': 0.25, 'language': 0.25}\n",
            "interactions: {'between': 1.0}\n",
            "between: {'computers': 1.0}\n",
            "computers: {'and': 1.0}\n",
            "and: {'human': 0.5, 'context': 0.5}\n",
            "human: {'(': 1.0}\n",
            "languages: {'.': 1.0}\n",
            ".: {'as': 0.3333333333333333, 'many': 0.3333333333333333, 'nlp': 0.3333333333333333}\n",
            "as: {'such': 1.0}\n",
            "such: {',': 1.0}\n",
            ",: {'which': 0.6666666666666666, 'nlp': 0.3333333333333333}\n",
            "related: {'to': 1.0}\n",
            "to: {'the': 1.0}\n",
            "area: {'of': 1.0}\n",
            "human-computer: {'interaction': 1.0}\n",
            "interaction: {'.': 1.0}\n",
            "many: {'nlp': 1.0}\n",
            "tasks: {'involve': 0.5, 'can': 0.5}\n",
            "involve: {'natural': 1.0}\n",
            "understanding: {',': 1.0}\n",
            "which: {'requires': 0.5, 'involves': 0.5}\n",
            "requires: {'comprehension': 1.0}\n",
            "comprehension: {'of': 1.0}\n",
            "meaning: {'and': 1.0}\n",
            "context: {'of': 1.0}\n",
            "can: {'also': 1.0}\n",
            "also: {'involve': 1.0}\n",
            "generation: {',': 1.0}\n",
            "involves: {'creating': 1.0}\n",
            "creating: {'coherent': 1.0}\n",
            "coherent: {'text': 1.0}\n",
            "text: {'based': 1.0}\n",
            "based: {'on': 1.0}\n",
            "on: {'some': 1.0}\n",
            "some: {'input': 1.0}\n",
            "input: {'.': 1.0}\n",
            "\n",
            "Next word prediction for 'natural':\n",
            "[('language', 0.75), (')', 0.25)]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Ensure you have the necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    tokens = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "    return [token for sublist in tokens for token in sublist]\n",
        "\n",
        "def compute_ngrams(tokens, n):\n",
        "    return list(ngrams(tokens, n))\n",
        "\n",
        "def bigram_probabilities(tokens):\n",
        "    bigrams = list(ngrams(tokens, 2))\n",
        "    fdist = FreqDist(bigrams)\n",
        "    cfdist = ConditionalFreqDist(bigrams)\n",
        "    probabilities = {}\n",
        "    for w1 in cfdist:\n",
        "        total = cfdist[w1].N()\n",
        "        probabilities[w1] = {w2: cfdist[w1][w2] / total for w2 in cfdist[w1]}\n",
        "    return probabilities\n",
        "\n",
        "def next_word_prediction(bigram_probs, word):\n",
        "    if word in bigram_probs:\n",
        "        return sorted(bigram_probs[word].items(), key=lambda x: x[1], reverse=True)\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Sample corpus\n",
        "text = \"\"\"\n",
        "Natural language processing (NLP) is a subfield of artificial intelligence (AI) concerned with the interactions\n",
        "between computers and human (natural) languages. As such, NLP is related to the area of human-computer interaction.\n",
        "Many NLP tasks involve natural language understanding, which requires comprehension of the meaning and context of the\n",
        "language. NLP tasks can also involve natural language generation, which involves creating coherent text based on some input.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocess the text\n",
        "tokens = preprocess_text(text)\n",
        "\n",
        "# Compute unigrams, bigrams, and trigrams\n",
        "unigrams = compute_ngrams(tokens, 1)\n",
        "bigrams = compute_ngrams(tokens, 2)\n",
        "trigrams = compute_ngrams(tokens, 3)\n",
        "\n",
        "# Compute bigram probabilities\n",
        "bigram_probs = bigram_probabilities(tokens)\n",
        "\n",
        "# Print results\n",
        "print(\"Unigrams:\")\n",
        "print(FreqDist(unigrams))\n",
        "\n",
        "print(\"\\nBigrams:\")\n",
        "print(FreqDist(bigrams))\n",
        "\n",
        "print(\"\\nTrigrams:\")\n",
        "print(FreqDist(trigrams))\n",
        "\n",
        "print(\"\\nBigram Probabilities:\")\n",
        "for w1, probs in bigram_probs.items():\n",
        "    print(f\"{w1}: {probs}\")\n",
        "\n",
        "print(\"\\nNext word prediction for 'natural':\")\n",
        "print(next_word_prediction(bigram_probs, 'natural'))\n"
      ]
    }
  ]
}